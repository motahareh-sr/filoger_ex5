{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import lib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# define block resnet\n",
        "def block_resnet(input, filter, stride):\n",
        "  x_i = input\n",
        "\n",
        "  x = Conv2D(filter, kernel_size=3, strides=stride, padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(tf.keras.activations.relu)(x)\n",
        "\n",
        "  x = Conv2D(filter, kernel_size=3, strides=1, padding='same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(tf.keras.activations.relu)(x)\n",
        "\n",
        "  x = Conv2D(filter, kernel_size=1, strides=stride)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x_i = Conv2D(filter, kernel_size=1, strides=stride)(x_i)\n",
        "  x_i = BatchNormalization()(x_i)\n",
        "\n",
        "  # add for skip layers\n",
        "  x = tf.keras.layers.Add()([x_i, x])\n",
        "  x = Activation(tf.keras.activations.relu)(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "# define main def for resnet\n",
        "def resnet18(input_shape, classes):\n",
        "  # first layer\n",
        "  input_layer = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "  # second layer\n",
        "  x = Conv2D(64, kernel_size=3, padding='same')(input_layer)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(tf.keras.activations.relu)(x)\n",
        "\n",
        "  x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
        "\n",
        "  # call the block\n",
        "  x = block_resnet(x, 64, 1)\n",
        "  x = block_resnet(x, 64, 1)\n",
        "  x = block_resnet(x, 128, 1)\n",
        "  x = block_resnet(x, 128, 1)\n",
        "  x = block_resnet(x, 256, 1)\n",
        "  x = block_resnet(x, 256, 1)\n",
        "  x = block_resnet(x, 512, 1)\n",
        "  x = block_resnet(x, 512, 1)\n",
        "\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Flatten()(x)\n",
        "\n",
        "  output = Dense(classes, activation='softmax')(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs=input_layer, outputs=output, name='resnet_model')\n",
        "\n",
        "  return model\n",
        "\n",
        "# get dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# make an object\n",
        "input_shape = (32, 32, 3)\n",
        "num_classes = 10\n",
        "r18 = resnet18(input_shape, num_classes)\n",
        "\n",
        "r18.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# for increase speed of train\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(50000).batch(32)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
        "\n",
        "# fit on data\n",
        "history = r18.fit(train_dataset, epochs=10)\n",
        "\n",
        "# test\n",
        "r18.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "VEzw6eebvX8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd60a090-14b5-4eaa-9f50-7fbcf2c232a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 170s 96ms/step - loss: 1.4107 - accuracy: 0.4824\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 150s 96ms/step - loss: 0.9915 - accuracy: 0.6463\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 150s 96ms/step - loss: 0.7926 - accuracy: 0.7259\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 150s 96ms/step - loss: 0.6657 - accuracy: 0.7704\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 150s 96ms/step - loss: 0.5775 - accuracy: 0.7996\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 150s 96ms/step - loss: 0.5113 - accuracy: 0.8240\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 150s 96ms/step - loss: 0.4531 - accuracy: 0.8439\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 150s 96ms/step - loss: 0.4076 - accuracy: 0.8594\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 150s 96ms/step - loss: 0.3616 - accuracy: 0.8757\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 150s 96ms/step - loss: 0.3193 - accuracy: 0.8896\n",
            "313/313 [==============================] - 10s 31ms/step - loss: 0.6561 - accuracy: 0.7913\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6560556888580322, 0.7912999987602234]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}